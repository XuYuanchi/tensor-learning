{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = \"center\">Intuitive Understanding of Randomized Singular Value Decomposition</h1>\n",
    "\n",
    "<h4 align = \"center\">A Python Implementation of SVD with Randomized Linear Algebra</h4>\n",
    "\n",
    "Matrix decomposition is a foundational tool for some critical applications like data compression, dimensionality reduction, and sparsity learning. In many cases, for purposes of approximating a data matrix by a low-rank structure, the Singular Value Decomposition (SVD) is the best choice. However, the accurate and efficient SVD of large-scale datasets is computationally challenging. To resolve the SVD in this situation, there are many algorithms have been developed by applying randomized linear algebra. One of the most important algorithms is randomized SVD, which is competitively efficient for factorizing any matrix with a relatively low rank.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img align=\"middle\" src=\"https://github.com/xinychen/tensor-learning/blob/master/images/svd_history.png\" width=\"700\" />\n",
    "</p>\n",
    "\n",
    "<h6 align=\"center\">\n",
    "<b>Figure 1</b>: A timeline of major SVD developments. (The picture is from [2]).\n",
    "</h6>\n",
    "\n",
    "\n",
    "This post will introduce the preliminary and essential idea of the randomized SVD. To help readers gain a better understanding of randomized SVD, we also provide the corresponding Python implementation in this post.\n",
    "\n",
    "> For reproducing this notebook, please clone or download the **tensor-learning** repository ([https://github.com/xinychen/tensor-learning](https://github.com/xinychen/tensor-learning)) on your computer first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary\n",
    "\n",
    "### SVD Formula\n",
    "\n",
    "As you may already know, SVD is one of the most important decomposition formula in linear algebra. For any given matrix $\\boldsymbol{A}$, SVD has the form of\n",
    "\\begin{equation}\n",
    "\\boldsymbol{A}=\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^\\top\n",
    "\\end{equation}\n",
    "where the matrices $\\boldsymbol{U}$ and $\\boldsymbol{V}$ consists of left and right singular vectors, respectively. The diagonal entries of $\\boldsymbol{\\Sigma}$ are singular values.\n",
    "\n",
    "### A Small Matrix Example\n",
    "\n",
    "Take a 3-by-3 matrix for example, we can compute the SVD by using `numpy.linalg.svd` in Python. Let us have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[-0.37421754  0.28475648 -0.88253894]\n",
      " [-0.56470638 -0.82485997 -0.02669705]\n",
      " [-0.7355732   0.48838486  0.46948087]]\n",
      "\n",
      "Singular values:\n",
      "[9.34265841 3.24497827 1.08850813]\n",
      "\n",
      "Right singular vectors:\n",
      "[[-0.57847229 -0.61642675 -0.53421706]\n",
      " [-0.73171177  0.10269066  0.67383419]\n",
      " [ 0.36051032 -0.78068732  0.51045041]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 3, 2],\n",
    "              [5, 3, 1],\n",
    "              [3, 4, 5]])\n",
    "u, s, v = np.linalg.svd(A, full_matrices = 0)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the singular values are 9.3427, 3.2450, and 1.0885."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized SVD\n",
    "\n",
    "### Essential Idea\n",
    "\n",
    "Randomized SVD can be broken into three steps. For any given $m$-by-$n$ matrix $\\boldsymbol{A}$, if we impose a target rank $k$ with $k < \\min\\{m, n\\}$, then the first step is to\n",
    "\n",
    "- 1) generate a Gaussian random matrix $\\boldsymbol{Î©}$ with size of $n$-by-$k$,\n",
    "- 2) compute a new $m$-by-$k$ matrix $\\boldsymbol{Y}$,\n",
    "- and 3) apply QR decomposition to the matrix $\\boldsymbol{Y}$.\n",
    "\n",
    "Note that the first step needs to return the $m$-by-$k$ matrix $\\boldsymbol{Q}$.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img align=\"middle\" src=\"https://github.com/xinychen/tensor-learning/blob/master/images/rsvd_step1.png\" width=\"600\" />\n",
    "</p>\n",
    "\n",
    "<h6 align=\"center\">\n",
    "<b>Figure 2</b>: The first step of randomized SVD. (The picture is from [2]).\n",
    "</h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rsvd(A, Omega):\n",
    "    Y = A @ Omega\n",
    "    Q, _ = np.linalg.qr(Y)\n",
    "    B = Q.T @ A\n",
    "    u_tilde, s, v = np.linalg.svd(B, full_matrices = 0)\n",
    "    u = Q @ u_tilde\n",
    "    return u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[ 0.38070859  0.60505354]\n",
      " [ 0.56830191 -0.74963644]\n",
      " [ 0.72944767  0.26824507]]\n",
      "\n",
      "Singular values:\n",
      "[9.34224023 3.02039888]\n",
      "\n",
      "Right singular vectors:\n",
      "[[ 0.57915029  0.61707064  0.53273704]\n",
      " [-0.77420021  0.21163814  0.59650929]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "A = np.array([[1, 3, 2],\n",
    "              [5, 3, 1],\n",
    "              [3, 4, 5]])\n",
    "rank = 2\n",
    "Omega = np.random.randn(A.shape[1], rank)\n",
    "u, s, v = rsvd(A, Omega)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def power_iteration(A, Omega, power_iter = 3):\n",
    "    Y = A @ Omega\n",
    "    for q in range(power_iter):\n",
    "        Y = A @ (A.T @ Y)\n",
    "    Q, _ = np.linalg.qr(Y)\n",
    "    return Q\n",
    "\n",
    "def rsvd(A, Omega):\n",
    "    Q = power_iteration(A, Omega)\n",
    "    B = Q.T @ A\n",
    "    u_tilde, s, v = np.linalg.svd(B, full_matrices = 0)\n",
    "    u = Q @ u_tilde\n",
    "    return u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[ 0.37421757  0.28528579]\n",
      " [ 0.56470638 -0.82484381]\n",
      " [ 0.73557319  0.48810317]]\n",
      "\n",
      "Singular values:\n",
      "[9.34265841 3.24497775]\n",
      "\n",
      "Right singular vectors:\n",
      "[[ 0.57847229  0.61642675  0.53421706]\n",
      " [-0.73178429  0.10284774  0.67373147]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "A = np.array([[1, 3, 2],\n",
    "              [5, 3, 1],\n",
    "              [3, 4, 5]])\n",
    "rank = 2\n",
    "Omega = np.random.randn(A.shape[1], rank)\n",
    "u, s, v = rsvd(A, Omega)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The central idea behind Randomized SVD\n",
    "\n",
    "\n",
    "#### Power Iterations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def power_iteration(mat, Phi, power_iter = 3):\n",
    "    B = mat @ Phi\n",
    "    for q in range(power_iter):\n",
    "        B = mat @ (mat.T @ B)\n",
    "    Q, _ = np.linalg.qr(B)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsvd(mat, rank, power_iter):\n",
    "    dim1, dim2 = mat.shape\n",
    "    Phi = np.random.randn(dim2, rank)\n",
    "    A = mat @ Phi\n",
    "    if power_iter > 0:\n",
    "        for k in range(power_iter):\n",
    "            A = mat @ (mat.T @ A)\n",
    "    Q, R = np.linalg.qr(A)\n",
    "    u_tilde, s, v = np.linalg.svd(Q.T @ mat, full_matrices = 0)\n",
    "    return Q @ u_tilde, s, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give a sufficiently detailed understanding with a small worked example. The problem is a simple SVD of 5-by-4 matrix, i.e.,\n",
    "$$\\boldsymbol{X}=\\left(\\begin{array}{cccc}\n",
    "1 & 3 & 2 & 4 \\\\\n",
    "5 & 3 & 1 & 2 \\\\\n",
    "3 & 4 & 5 & 2 \\\\\n",
    "4 & 4 & 2 & 1 \\\\\n",
    "4 & 2 & 3 & 3 \\\\\n",
    "\\end{array}\\right)\\in\\mathbb{R}^{5\\times 4}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[-0.35579275  0.61467653  0.58103306 -0.39692223]\n",
      " [-0.43905533 -0.5883267   0.34849729 -0.03803043]\n",
      " [-0.53040969  0.37421029 -0.65683124  0.0736076 ]\n",
      " [-0.44100936 -0.36870485 -0.24920217 -0.50936999]\n",
      " [-0.45256849  0.00823753  0.21776416  0.75903265]]\n",
      "\n",
      "Singular values:\n",
      "[13.1975984   3.6191375   2.70009861  1.85329644]\n",
      "\n",
      "Right singular vectors:\n",
      "[[-0.58469804 -0.5436866  -0.4578419  -0.39104205]\n",
      " [-0.7311674   0.0324791   0.49718495  0.46598977]\n",
      " [ 0.0841724  -0.14814801 -0.59949834  0.78202872]\n",
      " [ 0.34122931 -0.82547087  0.42870697  0.1355387 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([[1, 3, 2, 4],\n",
    "                [5, 3, 1, 2],\n",
    "                [3, 4, 5, 2],\n",
    "                [4, 4, 2, 1],\n",
    "                [4, 2, 3, 3]])\n",
    "u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[-0.35579222 -0.61522273  0.58260656]\n",
      " [-0.43905528  0.58827643  0.34864337]\n",
      " [-0.53040979 -0.37411357 -0.65711692]\n",
      " [-0.44100867  0.36799365 -0.24717929]\n",
      " [-0.45256952 -0.00717968  0.21474902]]\n",
      "\n",
      "Singular values:\n",
      "[13.1975984   3.61913492  2.70008736]\n",
      "\n",
      "Right singular vectors:\n",
      "[[-0.5846981  -0.54368644 -0.45784198 -0.39104207]\n",
      " [ 0.73141086 -0.03306811 -0.49688356 -0.46588774]\n",
      " [ 0.08323863 -0.14589787 -0.60066191  0.78165876]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank = 3\n",
    "power_iter = 3\n",
    "u, s, v = rsvd(mat, rank, power_iter)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[-0.37421754  0.28475648 -0.88253894]\n",
      " [-0.56470638 -0.82485997 -0.02669705]\n",
      " [-0.7355732   0.48838486  0.46948087]]\n",
      "\n",
      "Singular values:\n",
      "[9.34265841 3.24497827 1.08850813]\n",
      "\n",
      "Right singular vectors:\n",
      "[[-0.57847229 -0.61642675 -0.53421706]\n",
      " [-0.73171177  0.10269066  0.67383419]\n",
      " [ 0.36051032 -0.78068732  0.51045041]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([[1, 3, 2],\n",
    "                [5, 3, 1],\n",
    "                [3, 4, 5]])\n",
    "u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left singular vectors:\n",
      "[[ 0.37421764  0.28389005]\n",
      " [ 0.56470638 -0.82488578]\n",
      " [ 0.73557315  0.48884546]]\n",
      "\n",
      "Singular values:\n",
      "[9.34265841 3.24497688]\n",
      "\n",
      "Right singular vectors:\n",
      "[[ 0.57847229  0.61642676  0.53421705]\n",
      " [-0.73159303  0.1024336   0.67400222]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank = 2\n",
    "power_iter = 3\n",
    "u, s, v = rsvd(mat, rank, power_iter)\n",
    "print('Left singular vectors:')\n",
    "print(u)\n",
    "print()\n",
    "print('Singular values:')\n",
    "print(s)\n",
    "print()\n",
    "print('Right singular vectors:')\n",
    "print(v)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4743.47345882   56.30120971   56.14880174   56.13332907   56.03742922\n",
      "   56.00312683   55.98918016   55.8925917    55.86384718   55.80551466]\n",
      "387.3423180580139\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mat = np.random.rand(10000, 9000)\n",
    "start = time.time()\n",
    "U, S, V = fast_svd(mat)\n",
    "end = time.time()\n",
    "print(np.diag(S[:10]))\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4743.47345882   52.08820533   52.03989705   51.98184477   51.84658782\n",
      "   51.78052861   51.68910186   51.59906955   51.51632298   51.43246594]\n",
      "1.8465938568115234\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "U, S, V = rsvd(mat, 100, 2)\n",
    "end = time.time()\n",
    "print(np.diag(S[:10]))\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this post, you discovered the randomized linear algebra method for SVD.\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "- The essential idea of randomized SVD.\n",
    "- How to implement randomized SVD step-by-step.\n",
    "\n",
    "Do you have any question? Ask your question by creating an issue at the **tensor-learning** repository ([https://github.com/xinychen/tensor-learning](https://github.com/xinychen/tensor-learning)) and I will do my best to answer. If you find these codes useful, please star (â) this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Per-Gunnar Martinsson (2016). Randomized methods for matrix computations and analysis of high dimensional data. arXiv:1607.01649. [[PDF](https://arxiv.org/pdf/1607.01649v1.pdf)]\n",
    "\n",
    "[2] N. Benjamin Erichson, Sergey Voronin, Steven L. Brunton, J. Nathan Kutz (2016). Randomized Matrix Decompositions Using R. arXiv:1608.02148. [[PDF](https://arxiv.org/pdf/1608.02148.pdf)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
