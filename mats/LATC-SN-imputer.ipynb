{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Rank Autoregressive Tensor Completion Imputer (LATC-imputer)\n",
    "\n",
    "This notebook shows how to implement a LATC (with Schatten $p$-norm) imputer on three real-world data sets (i.e., PeMS traffic speed data, Guangzhou traffic speed data, Electricity data). To overcome the problem of missing values within multivariate time series data, this method takes into account both low-rank structure and time series regression. For an in-depth discussion of LATC-imputer, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Jinming Yang, Lijun Sun (2020). <b>Low-Rank Autorgressive Tensor Completion for Multivariate Time Series Forecasting</b>. arXiv:2006.10436. <a href=\"https://arxiv.org/abs/2006.10436\" title=\"PDF\"><b>[PDF]</b></a> \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LATC-imputer kernel\n",
    "\n",
    "We start by introducing some necessary functions that relies on `Numpy`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>ten2mat</code>:</b> <font color=\"black\">Unfold tensor as matrix by specifying mode.</font></li>\n",
    "<li><b><code>mat2ten</code>:</b> <font color=\"black\">Fold matrix as tensor by specifying dimension (i.e, tensor size) and mode.</font></li>\n",
    "<li><b><code>svt</code>:</b> <font color=\"black\">Implement the process of Singular Value Thresholding (SVT).</font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt_sn(mat, tau, p, sv):\n",
    "    tau = p * np.power(sv, p - 1) * tau\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    vec = s[:idx] - tau[:idx]\n",
    "    return u[:, : idx] @ np.diag(vec) @ v[: idx, :], s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>compute_mape</code>:</b> <font color=\"black\">Compute the value of Mean Absolute Percentage Error (MAPE).</font></li>\n",
    "<li><b><code>compute_rmse</code>:</b> <font color=\"black\">Compute the value of Root Mean Square Error (RMSE).</font></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> Note that $$\\mathrm{MAPE}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left|y_{i}-\\hat{y}_{i}\\right|}{y_{i}} \\times 100, \\quad\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}},$$ where $n$ is the total number of estimated values, and $y_i$ and $\\hat{y}_i$ are the actual value and its estimation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind LATC-imputer is to approximate partially observed data with both low-rank structure and time series dynamics. The following `imputer` kernel includes some necessary inputs:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>dense_tensor</code>:</b> <font color=\"black\">This is an input which has the ground truth for validation. If this input is not available, you could use <code>dense_tensor = sparse_tensor.copy()</code> instead.</font></li>\n",
    "<li><b><code>sparse_tensor</code>:</b> <font color=\"black\">This is a partially observed tensor which has many missing entries.</font></li>\n",
    "<li><b><code>time_lags</code>:</b> <font color=\"black\">Time lags, e.g., <code>time_lags = np.array([1, 2, 3])</code>. </font></li>\n",
    "<li><b><code>alpha</code>:</b> <font color=\"black\">Weights for tensors' nuclear norm, e.g., <code>alpha = np.ones(3) / 3</code>. </font></li>\n",
    "<li><b><code>rho</code>:</b> <font color=\"black\">Learning rate for ADMM, e.g., <code>rho = 0.0005</code>. </font></li>\n",
    "<li><b><code>lambda0</code>:</b> <font color=\"black\">Weight for time series regressor, e.g., <code>lambda0 = 5 * rho</code>. If <code>lambda0 = 0</code>, then this imputer is actually a standard low-rank tensor completion (i.e., High-accuracy Low-Rank Tensor Completion, or HaLRTC).</font></li>\n",
    "<li><b><code>epsilon</code>:</b> <font color=\"black\">Stop criteria, e.g., <code>epsilon = 0.001</code>. </font></li>\n",
    "<li><b><code>maxiter</code>:</b> <font color=\"black\">Maximum iteration to stop algorithm, e.g., <code>maxiter = 50</code>. </font></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho0, lambda0, p, epsilon, maxiter):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion, LATC-imputer.\"\"\"\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = np.int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    max_lag = np.max(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    \n",
    "    X = np.zeros(np.insert(dim, 0, len(dim))) # \\boldsymbol{\\mathcal{X}}\n",
    "    T = np.zeros(np.insert(dim, 0, len(dim))) # \\boldsymbol{\\mathcal{T}}\n",
    "    Z = sparse_mat.copy()                     # \\boldsymbol{Z}\n",
    "    Z[pos_missing] = np.mean(sparse_mat[sparse_mat != 0])\n",
    "    A = 0.001 * np.random.rand(dim[0], d)     # \\boldsymbol{A}\n",
    "    it = 0\n",
    "    sv = []\n",
    "    for k in range(len(dim)):\n",
    "        _, s, _ = np.linalg.svd(ten2mat(sparse_tensor, k), full_matrices = 0)\n",
    "        sv.append(s)\n",
    "    ind = np.zeros((d, dim_time - max_lag), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(max_lag - time_lags[i], dim_time - time_lags[i])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    rho = rho0\n",
    "    while True:\n",
    "        rho = min(rho * 1.05, 1e5)\n",
    "        for k in range(len(dim)):\n",
    "            temp, sv0 = svt_sn(ten2mat(mat2ten(Z, dim, 0) - T[k] / rho, k), alpha[k] / rho, p, sv[k])\n",
    "            X[k] = mat2ten(temp, dim, k)\n",
    "            sv[k] = sv0\n",
    "        tensor_hat = np.einsum('k, kmnt -> mnt', alpha, X)\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        mat0 = np.zeros((dim[0], dim_time - max_lag))\n",
    "        if lambda0 > 0:\n",
    "            for m in range(dim[0]):\n",
    "                Qm = mat_hat[m, ind].T\n",
    "                A[m, :] = np.linalg.pinv(Qm) @ Z[m, max_lag :]\n",
    "                mat0[m, :] = Qm @ A[m, :]\n",
    "            mat1 = ten2mat(np.mean(rho * X + T, axis = 0), 0)\n",
    "            Z[pos_missing] = np.append((mat1[:, : max_lag] / rho), (mat1[:, max_lag :] + lambda0 * mat0) \n",
    "                                       / (rho + lambda0), axis = 1)[pos_missing]\n",
    "        else:\n",
    "            Z[pos_missing] = (ten2mat(np.mean(X + T / rho, axis = 0), 0))[pos_missing]\n",
    "        T = T + rho * (X - np.broadcast_to(mat2ten(Z, dim, 0), np.insert(dim, 0, len(dim))))\n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 100 == 0:\n",
    "            print('Iter: {}'.format(it))\n",
    "            print('Tolerance: {:.6}'.format(tol))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "            print()\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    print('Total iteration: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guangzhou data\n",
    "\n",
    "We generate **random missing (RM)** values on Guangzhou traffic speed data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_tensor,binary_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `imputer` to fill in the missing entries and measure performance metrics on the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 56\n",
      "Tolerance: 9.86698e-05\n",
      "Imputation MAPE: 0.0665109\n",
      "Imputation RMSE: 2.96183\n",
      "\n",
      "Running time: 85 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_tensor,binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 60\n",
      "Tolerance: 9.96719e-05\n",
      "Imputation MAPE: 0.0719049\n",
      "Imputation RMSE: 3.19905\n",
      "\n",
      "Running time: 92 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')\n",
    "random_tensor = random_tensor['random_tensor']\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_tensor,binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 66\n",
      "Tolerance: 9.78971e-05\n",
      "Imputation MAPE: 0.0801275\n",
      "Imputation RMSE: 3.52658\n",
      "\n",
      "Running time: 99 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate **non-random missing (NM)** values on Guangzhou traffic speed data set. Then, we conduct the imputation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 52\n",
      "Tolerance: 9.90001e-05\n",
      "Imputation MAPE: 0.102839\n",
      "Imputation RMSE: 4.20345\n",
      "\n",
      "Running time: 79 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 62\n",
      "Tolerance: 9.62616e-05\n",
      "Imputation MAPE: 0.107762\n",
      "Imputation RMSE: 4.37343\n",
      "\n",
      "Running time: 99 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')\n",
    "dense_tensor = tensor['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')\n",
    "random_matrix = random_matrix['random_matrix']\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "\n",
    "dense_tensor = np.transpose(dense_tensor, [0, 2, 1])\n",
    "sparse_tensor = np.transpose(sparse_tensor, [0, 2, 1])\n",
    "\n",
    "del tensor, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 82\n",
      "Tolerance: 9.68937e-05\n",
      "Imputation MAPE: 0.117346\n",
      "Imputation RMSE: 4.68301\n",
      "\n",
      "Running time: 146 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 142, 143, 144, 145, 146, 147])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PeMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_tensor = np.load('../datasets/PeMS-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 17\n",
      "Tolerance: 9.9813e-05\n",
      "Imputation MAPE: 0.0304862\n",
      "Imputation RMSE: 2.35991\n",
      "\n",
      "Running time: 47 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_tensor = np.load('../datasets/PeMS-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iteration: 35\n",
      "Tolerance: 8.66137e-05\n",
      "Imputation MAPE: 0.0351956\n",
      "Imputation RMSE: 2.77947\n",
      "\n",
      "Running time: 113 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_tensor = np.load('../datasets/PeMS-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 5 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_matrix = np.load('../datasets/PeMS-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 288, 44))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(44):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_matrix = np.load('../datasets/PeMS-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 288, 44))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(44):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/PeMS-data-set/pems.npy')\n",
    "random_matrix = np.load('../datasets/PeMS-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 288, 44))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(44):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 286, 287, 288, 289, 290, 291])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-4\n",
    "lambda0 = 1 * rho\n",
    "p = 0.7\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electricity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random Missing (RM)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_tensor = np.load('../datasets/Electricity-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_tensor = np.load('../datasets/Electricity-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_tensor = np.load('../datasets/Electricity-data-set/random_tensor.npy')\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Random missing (RM) scenario:\n",
    "binary_tensor = np.round(random_tensor + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, ten2mat(binary_tensor, 0))\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_tensor, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Nonrandom Missing (NM)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_matrix = np.load('../datasets/Electricity-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.2\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 24, 35))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(35):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_matrix = np.load('../datasets/Electricity-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 24, 35))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(35):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mat = np.load('../datasets/Electricity-data-set/electricity35.npy')\n",
    "random_matrix = np.load('../datasets/Electricity-data-set/random_matrix.npy')\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "### Nonrandom missing (NM) scenario:\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 24, 35))\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(35):\n",
    "        binary_tensor[i1,:,i2] = np.round(random_matrix[i1,i2] + 0.5 - missing_rate)\n",
    "binary_mat = ten2mat(binary_tensor, 0)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "\n",
    "sparse_tensor = mat2ten(sparse_mat, np.array(binary_tensor.shape), 0)\n",
    "dense_tensor = mat2ten(dense_mat, np.array(binary_tensor.shape), 0)\n",
    "\n",
    "del dense_mat, random_matrix, binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "time_lags = np.array([1, 2, 3, 4, 5, 6, 22, 23, 24, 25, 26, 27])\n",
    "alpha = np.ones(3) / 3\n",
    "rho = 1e-6\n",
    "lambda0 = 5 * rho\n",
    "p = 0.9\n",
    "epsilon = 1e-4\n",
    "maxiter = 100\n",
    "tensor_hat = imputer(dense_tensor, sparse_tensor, time_lags, alpha, rho, lambda0, p, epsilon, maxiter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
